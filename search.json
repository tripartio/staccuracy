[{"path":"https://tripartio.github.io/staccuracy/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Chitu Okoli Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tripartio.github.io/staccuracy/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Chitu Okoli. Author, maintainer.","code":""},{"path":"https://tripartio.github.io/staccuracy/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Okoli C (2025). staccuracy: Standardized Accuracy Model Performance Metrics. R package version 0.2.2, https://tripartio.github.io/staccuracy/, https://github.com/tripartio/staccuracy.","code":"@Manual{,   title = {staccuracy: Standardized Accuracy and Other Model Performance Metrics},   author = {Chitu Okoli},   year = {2025},   note = {R package version 0.2.2, https://tripartio.github.io/staccuracy/},   url = {https://github.com/tripartio/staccuracy}, }"},{"path":"https://tripartio.github.io/staccuracy/index.html","id":"staccuracy","dir":"","previous_headings":"","what":"Standardized Accuracy and Other Model Performance Metrics","title":"Standardized Accuracy and Other Model Performance Metrics","text":"Standardized accuracy (staccuracy) framework expressing accuracy scores 50% represents reference level performance 100% perfect prediction. staccuracy package provides tools creating staccuracy functions well recommended staccuracy measures. also provides functions classic performance metrics mean absolute error (MAE), root mean squared error (RMSE), area receiver operating characteristic curve (AUCROC), well winsorized versions applicable.","code":""},{"path":"https://tripartio.github.io/staccuracy/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Standardized Accuracy and Other Model Performance Metrics","text":"can install official CRAN version staccuracy: development version staccuracy thoroughly tested, might thoroughly documented. can install like :","code":"install.packages('staccuracy') # install.packages(\"pak\") pak::pak(\"tripartio/staccuracy\")"},{"path":"https://tripartio.github.io/staccuracy/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Standardized Accuracy and Other Model Performance Metrics","text":"basic challenge staccuracy addresses measure accuracy model predictions intuitively indicate relevant accuracy scores :","code":"library(staccuracy) #>  #> Attaching package: 'staccuracy' #> The following object is masked from 'package:stats': #>  #>     mad  # Here's some data actual_1 <- c(2.3, 4.5, 1.8, 7.6, 3.2)  # Here are some predictions of that data predicted_1 <- c(2.5, 4.2, 1.9, 7.4, 3.0)  # Mean Absolute Error (MAE) measures the average error in the predictions mae(actual_1, predicted_1) #> [1] 0.2  # But how good is that?  # Mean Absolute Deviation (MAD) gives the natural variation in the actual data around the mean; this is a point of comparison for the MAE. mad(actual_1) #> [1] 1.736  # So, our predictions are better (lower) than the MAD, but how good, really? # Create a standardized accuracy function to give us an easily interpretable metric: my_mae_vs_mad_sa <- staccuracy(mae, mad) my_mae_vs_mad_sa(actual_1, predicted_1) #> [1] 0.9423963  # That's 94.2% standardized accuracy compared to the MAD. Pretty good!  # This and other convenient standardized accuracy scores are already built in sa_mae_mad(actual_1, predicted_1)  # staccuracy of MAE on MAD #> [1] 0.9423963 sa_rmse_sd(actual_1, predicted_1)  # staccuracy of RMSE on SD #> [1] 0.95477"},{"path":"https://tripartio.github.io/staccuracy/reference/aucroc.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the ROC curve — aucroc","title":"Area under the ROC curve — aucroc","text":"Returns area ROC curve based comparing predicted scores actual binary values. Tied predictions handled calculating optimistic AUC (positive cases sorted first, resulting higher AUC) pessimistic AUC (positive cases sorted last, resulting lower AUC) returning average two. ROC, \"tie\" means least one pair pred predictions whose value identical yet corresponding values actual different. (value actual identical predictions, unproblematic considered \"ties\".)","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/aucroc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the ROC curve — aucroc","text":"","code":"aucroc(   actual,   pred,   na.rm = FALSE,   positive = NULL,   sample_size = 10000,   seed = 0 )"},{"path":"https://tripartio.github.io/staccuracy/reference/aucroc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the ROC curve — aucroc","text":"actual atomic vector. Actual label values dataset. must binary; , must exactly two distinct values (missing values, allowed). \"true\" \"positive\" class determined coercing actual logical TRUE FALSE following rules .logical(). intended meaning \"positive\", specify two values considered TRUE argument positive. pred numeric vector. Predictions corresponding respective element actual. numeric value (probabilities) permissible. na.rm logical(1). TRUE missing values removed; FALSE retained. TRUE, element either actual pred missing, paired element also removed. positive single atomic value. value actual considered TRUE; value actual considered FALSE. example, 2 means TRUE 1 means FALSE, set positive = 2. sample_size single positive integer. keep computation relatively rapid, actual pred longer sample_size elements, random sample sample_size actual pred selected ROC AUC calculated sample. disable random sampling long inputs, set sample_size = NA. seed numeric(1). Random seed used length(actual) > sample_size.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/aucroc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the ROC curve — aucroc","text":"List following elements: roc_opt: tibble optimistic ROC data. \"Optimistic\" means predictions tied, TRUE/positive actual values ordered FALSE/negative ones. roc_pess: tibble pessimistic ROC data. \"Pessimistic\" means predictions tied, FALSE/negative actual values ordered TRUE/positive ones. Note difference merely sort order: ties, way true positives, true negatives, etc. counted different optimistic pessimistic approaches. tied predictions, roc_opt roc_pess identical. auc_opt: area ROC curve optimistic ROC. auc_pess: area ROC curve pessimistic ROC. auc: mean auc_opt auc_pess. tied predictions, auc_opt, auc_pess, auc identical. ties: TRUE two tied predictions; FALSE ties.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/aucroc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the ROC curve — aucroc","text":"","code":"set.seed(0) # Generate some simulated \"actual\" data a <- sample(c(TRUE, FALSE), 50, replace = TRUE)  # Generate some simulated predictions p <- runif(50) |> round(2) p[c(7, 8, 22, 35, 40, 41)] <- 0.5  # Calculate AUCROC with its components ar <- aucroc(a, p) ar$auc #> [1] 0.46875"},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression error and deviation measures — mae","title":"Regression error and deviation measures — mae","text":"standard error deviation measures numeric data. \"Deviation\" means natural variation values numeric vector around central tendency (usually mean median). \"Error\" means average discrepancy actual values numeric vector predicted values.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression error and deviation measures — mae","text":"","code":"mae(actual, pred, na.rm = FALSE)  rmse(actual, pred, na.rm = FALSE)  mad(x, na.rm = FALSE, version = \"mean\", ...)"},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression error and deviation measures — mae","text":"actual numeric vector. Actual (true) values target outcome data. pred numeric vector. Predictions corresponding respective element actual. na.rm logical(1). TRUE missing values removed; FALSE retained. TRUE, element either actual pred missing, paired element also removed. x numeric vector. Values calculate MAD. version character(1). default (version = 'mean'), mad() returns mean absolute deviation (MAD) values relative mean. version = 'median', calls stats::mad() function instead, median absolute deviation relative median (MedAD, sometimes also called MAD). value gives error. See details. ... Arguments pass stats::mad() version = 'median'. See version argument details.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression error and deviation measures — mae","text":"cases, value actual pred NA na.rm = FALSE, function returns NA. mae() returns mean absolute error (MAE) predicted values pred compared actual values. rmse() returns root mean squared error (RMSE) predicted values pred compared actual values. mad() returns either mean absolute deviation (MAD) values relative mean (default) median absolute deviation relative median. See details.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regression error and deviation measures — mae","text":"Mean absolute deviation (MAD) mad() returns mean absolute deviation (MAD) values relative mean. useful default benchmark mean absolute error (MAE), standard deviation (SD) default benchmark root mean square error (RMSE). NOTE: function name overrides stats::mad() (median absolute deviation relative median). maintain functionality stats::mad(), specify version argument.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression error and deviation measures — mae","text":"","code":"a <- c(3, 5, 2, 7, 9, 4, 6, 8, 1, 10) p <- c(2.5, 5.5, 2, 6.5, 9.5, 3.5, 6, 7.5, 1.5, 9.5) mae(a, p) #> [1] 0.4  rmse(a, p) #> [1] 0.4472136  mad(a) #> [1] 2.5"},{"path":"https://tripartio.github.io/staccuracy/reference/reg_aucroc.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the ROC curve for regression target outcomes — reg_aucroc","title":"Area under the ROC curve for regression target outcomes — reg_aucroc","text":"Area ROC curve (AUCROC) classification measure. dichotomizing range actual values, reg_aucroc() turns regression evaluation classification evaluation regression model. Note model generates predictions assumed regression model; however, numeric inputs allowed pred argument, check nature source model.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg_aucroc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the ROC curve for regression target outcomes — reg_aucroc","text":"","code":"reg_aucroc(   actual,   pred,   num_quants = 100,   ...,   cuts = NULL,   imbalance = 0.05,   na.rm = FALSE,   sample_size = 10000,   seed = 0 )"},{"path":"https://tripartio.github.io/staccuracy/reference/reg_aucroc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the ROC curve for regression target outcomes — reg_aucroc","text":"actual numeric vector. Actual label values dataset. must numeric. pred numeric vector. Predictions corresponding respective element actual. num_quants scalar positive integer. cuts NULL (default), actual dichotomized quants quantiles many ROCs returned rocs element. However, cuts specified, quants ignored. ... used. Forces explicit naming arguments follow. cuts numeric vector. cuts provided, overrides quants specify cut points dichotomization actual creation cuts + 1 ROCs. imbalance numeric(1) (0, 0.5]. result element mean_auc averages AUCs three regions (see details return value). imbalance supposed percentage less frequent class data. provided, defaults 0.05 (5%). na.rm See documentation aucroc() sample_size See documentation aucroc(). addition notes, reg_aucroc(), sampling conducted dichotomization actual classification ROCs based identical data. seed See documentation aucroc()","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg_aucroc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the ROC curve for regression target outcomes — reg_aucroc","text":"List following elements: rocs: List results aucroc() dichotomized segment actual. auc: named numeric vector AUC extracted element rocs. Named percentile AUC represents. mean_auc: named numeric(3). average AUC low, middle, high quantiles dichotomization: lo: average AUC imbalance% (e.g., 5%) less actual target values; mid: average AUC lo hi; hi: average AUC (1 - imbalance)% (e.g., 95%) actual target values;","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg_aucroc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Area under the ROC curve for regression target outcomes — reg_aucroc","text":"ROC data AUCROC values calculated aucroc().","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg_aucroc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the ROC curve for regression target outcomes — reg_aucroc","text":"","code":"# Remove rows with missing values from airquality dataset airq <- airquality |>   na.omit()  # Create binary version where the target variable 'Ozone' is dichotomized based on its median airq_bin <- airq airq_bin$Ozone <- airq_bin$Ozone >= median(airq_bin$Ozone)  # Create a generic regression model; use autogam req_aq   <- autogam::autogam(airq, 'Ozone', family = gaussian()) #> Warning: basis dimension, k, increased to minimum possible req_aq$perf$sa_wmae_mad  # Standardized accuracy for regression #> NULL  # Create a generic classification model; use autogam class_aq <- autogam::autogam(airq_bin, 'Ozone', family = binomial()) #> Warning: basis dimension, k, increased to minimum possible class_aq$perf$auc  # AUC (standardized accuracy for classification) #> NULL  # Compute AUC for regression predictions reg_auc_aq <- reg_aucroc(   airq$Ozone,   predict(req_aq) )  # Average AUC over the lo, mid, and hi quantiles of dichotomization: reg_auc_aq$mean_auc #>        lo       mid        hi  #> 0.8541380 0.9398248 0.9876410"},{"path":"https://tripartio.github.io/staccuracy/reference/sa_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical tests for the differences between standardized accuracies (staccuracies) — sa_diff","title":"Statistical tests for the differences between standardized accuracies (staccuracies) — sa_diff","text":"distribution staccuracies uncertain (indeed, different staccuracies likely different distributions), bootstrapping used empirically estimate distributions calculate p-values. See return value description details function provides.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/sa_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical tests for the differences between standardized accuracies (staccuracies) — sa_diff","text":"","code":"sa_diff(   actual,   preds,   ...,   na.rm = FALSE,   sa = NULL,   pct = c(0.01, 0.02, 0.03, 0.04, 0.05),   boot_alpha = 0.05,   boot_it = 1000,   seed = 0 )"},{"path":"https://tripartio.github.io/staccuracy/reference/sa_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical tests for the differences between standardized accuracies (staccuracies) — sa_diff","text":"actual numeric vector. actual (true) labels. preds named list least two numeric vectors. element vector length actual predictions row corresponding element actual. names list elements names models produced respective prediction; names used distinguish results. ... used. Forces explicit naming subsequent arguments. na.rm See documentation staccuracy() sa list functions. element unquoted name valid staccuracy function (see staccuracy() required function signature.) element named, name displayed value sa column result. Otherwise, function name displayed. NULL (default), staccuracy functions automatically selected based datatypes actual preds. pct numeric values (0, 1). percentage values difference staccuracies tested. boot_alpha numeric(1) 0 1. Alpha percentile-based confidence interval range bootstrapped means; bootstrap confidence intervals lowest highest (1 - 0.05) / 2 percentiles. example, boot_alpha = 0.05 (default), intervals 2.5 97.5 percentiles. boot_it positive integer(1). number bootstrap iterations. seed integer(1). Random seed bootstrap sampling. Supply runs assure identical results.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/sa_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical tests for the differences between standardized accuracies (staccuracies) — sa_diff","text":"tibble staccuracy difference results: staccuracy: name staccuracy measure pred: named element (model name) input preds. row values give staccuracy prediction. pred NA, row represents difference prediction staccuracies (diff) instead  staccuracies . diff: diff takes form 'model1-model2', row values give difference staccuracies two named elements (model names) input preds. diff NA, row instead represents staccuracy specific model prediction (pred). lo, mean, hi: lower bound, mean, upper bound bootstrapped staccuracy. lower upper bounds confidence intervals specified input boot_alpha. p__: p-values difference staccuracies least specified percentage amount greater.  E.g., default input pct = c(0.01, 0.02, 0.03, 0.04, 0.05), columns p01, p02, p03, p04,  p05. apply differences staccuracies, provided diff rows NA pred rows. example meaning, mean difference 'model1-model2' 0.0832 p01 0.012 p02 0.035, 1.2% bootstrapped staccuracies model1 - model2 difference less 0.01 3.5% less 0.02. (, 98.8% differences greater 0.01 96.5% greater 0.02.)","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/sa_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical tests for the differences between standardized accuracies (staccuracies) — sa_diff","text":"","code":"lm_attitude_all <- lm(rating ~ ., data = attitude) lm_attitude__a <- lm(rating ~ . - advance, data = attitude) lm_attitude__c <- lm(rating ~ . - complaints, data = attitude)  sdf <- sa_diff(   attitude$rating,   list(     all = predict(lm_attitude_all),     madv = predict(lm_attitude__a),     mcmp = predict(lm_attitude__c)   ),   boot_it = 10 ) sdf #> # A tibble: 12 × 11 #>    staccuracy    pred  diff            lo    mean     hi     p01     p02     p03 #>    <chr>         <chr> <chr>        <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl> #>  1 WinMAE on MAD all   NA         0.672   0.719   0.776  NA      NA      NA      #>  2 WinMAE on MAD madv  NA         0.640   0.705   0.767  NA      NA      NA      #>  3 WinMAE on MAD mcmp  NA         0.586   0.635   0.692  NA      NA      NA      #>  4 WinMAE on MAD NA    all-madv  -0.00660 0.0139  0.0369  0.455   0.727   0.818  #>  5 WinMAE on MAD NA    all-mcmp   0.0440  0.0840  0.133   0.0909  0.0909  0.0909 #>  6 WinMAE on MAD NA    madv-mcmp  0.0291  0.0702  0.122   0.0909  0.0909  0.182  #>  7 WinRMSE on SD all   NA         0.684   0.737   0.781  NA      NA      NA      #>  8 WinRMSE on SD madv  NA         0.670   0.732   0.782  NA      NA      NA      #>  9 WinRMSE on SD mcmp  NA         0.616   0.670   0.723  NA      NA      NA      #> 10 WinRMSE on SD NA    all-madv  -0.00781 0.00529 0.0272  0.636   0.909   0.909  #> 11 WinRMSE on SD NA    all-mcmp   0.0335  0.0666  0.107   0.0909  0.0909  0.182  #> 12 WinRMSE on SD NA    madv-mcmp  0.0273  0.0613  0.108   0.0909  0.0909  0.182  #> # ℹ 2 more variables: p04 <dbl>, p05 <dbl>"},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized Accuracy and Other Model Performance Metrics — staccuracy-package","title":"Standardized Accuracy and Other Model Performance Metrics — staccuracy-package","text":"Standardized accuracy (staccuracy) framework expressing accuracy scores 50% represents reference level performance 100% perfect prediction. 'staccuracy' package provides tools creating staccuracy functions well recommended staccuracy measures. also provides functions classic performance metrics mean absolute error (MAE), root mean squared error (RMSE), area receiver operating characteristic curve (AUCROC), well winsorized versions applicable.","code":""},{"path":[]},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Standardized Accuracy and Other Model Performance Metrics — staccuracy-package","text":"Chitu Okoli Chitu.Okoli@skema.edu","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized accuracy (staccuracy) functions. — staccuracy","title":"Standardized accuracy (staccuracy) functions. — staccuracy","text":"Standardized accuracy (staccuracy) represents error accuracy measures scale 1 100% means perfect prediction 0.5 50% reference comparison specified standard performance. Higher 0.5 better reference 0.5 worse. 0 might might special meaning; sometimes negative scores possible, often indicate modelling errors. core function staccuracy(), receives input generic error function reference function compare error function performance. addition, following recommended staccuracy functions provided: sa_mae_mad: standardized accuracy mean absolute error (MAE) based mean absolute deviation (MAD) sa_rmse_sd: standardized accuracy root mean squared error (RMSE) based standard deviation (SD) sa_wmae_mad: standardized accuracy winsorized mean absolute error (MAE) based mean absolute deviation (MAD) sa_wrmse_sd: standardized accuracy winsorized root mean squared error (RMSE) based standard deviation (SD)","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized accuracy (staccuracy) functions. — staccuracy","text":"","code":"staccuracy(error_fun, ref_fun)  sa_mae_mad(actual, pred, na.rm = FALSE)  sa_wmae_mad(actual, pred, na.rm = FALSE)  sa_rmse_sd(actual, pred, na.rm = FALSE)  sa_wrmse_sd(actual, pred, na.rm = FALSE)"},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardized accuracy (staccuracy) functions. — staccuracy","text":"error_fun function. unquoted name function calculates error (accuracy) measure. function must signature function(actual, pred, na.rm = FALSE). ref_fun function. unquoted name function calculates reference error, accuracy, deviation measure. function must signature ref_fun(actual, na.rm = FALSE). actual numeric. true (actual) labels. pred numeric. predicted estimates. Must length actual. na.rm logical(1). Whether NA values removed (TRUE) (FALSE, default).","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardized accuracy (staccuracy) functions. — staccuracy","text":"staccuracy() returns function signature function(actual, pred, na.rm = FALSE) receives actual pred vector inputs returns staccuracy originally input error function based input reference function. convenience sa_*() functions return staccuracy measures specified .","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standardized accuracy (staccuracy) functions. — staccuracy","text":"core function staccuracy() receives input generic error function reference function compare error function's performance. input functions must following signatures (see argument specifications details arguments): error_fun: function(actual, pred, na.rm = na.rm); output must scalar numeric (, single number). error_fun: function(actual, pred, na.rm = na.rm); output must scalar numeric (, single number).","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardized accuracy (staccuracy) functions. — staccuracy","text":"","code":"# Here's some data actual_1 <- c(2.3, 4.5, 1.8, 7.6, 3.2)  # Here are some predictions of that data predicted_1 <- c(2.5, 4.2, 1.9, 7.4, 3.0)  # MAE measures the average error in the predictions mae(actual_1, predicted_1) #> [1] 0.2  # But how good is that? # MAD gives the natural variation in the actual data; this is a point of comparison. mad(actual_1) #> [1] 1.736  # So, our predictions are better (lower) than the MAD, but how good, really? # Create a standardized accuracy function to give us an easily interpretable metric: my_mae_vs_mad_sa <- staccuracy(mae, mad)  # Now use it my_mae_vs_mad_sa(actual_1, predicted_1) #> [1] 0.9423963  # That's 94.2% standardized accuracy compared to the MAD. Pretty good!"},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":null,"dir":"Reference","previous_headings":"","what":"Winsorize a numeric vector — winsorize","title":"Winsorize a numeric vector — winsorize","text":"Winsorization means truncating extremes numeric range replacing extreme values predetermined minimum maximum. winsorize() returns input vector values values less greater provided minimum maximum replaced provided minimum maximum, respectively. win_mae() win_rmse() return MAE RMSE respectively winsorized predictions. fundamental idea underlying winsorization predictions actual data well-defined bounds, models penalized overzealous predicting beyond extremes data. Models overzealous boundaries might sometimes superior within normal ranges; extremes can easily corrected winsorization.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Winsorize a numeric vector — winsorize","text":"","code":"winsorize(x, win_range)  win_mae(actual, pred, win_range = range(actual), na.rm = FALSE)  win_rmse(actual, pred, win_range = range(actual), na.rm = FALSE)"},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Winsorize a numeric vector — winsorize","text":"x numeric vector. win_range numeric(2). minimum maximum allowable values pred predictions x. functions pred, win_range defaults minimum maximum values provided actual values. functions x, default. actual numeric vector. Actual (true) values target outcome data. pred numeric vector. Predictions corresponding respective element actual. na.rm logical(1). TRUE missing values removed; FALSE retained. TRUE, element either actual pred missing, paired element also removed.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Winsorize a numeric vector — winsorize","text":"winsorize() returns winsorized vector. win_mae() returns mean absolute error (MAE) winsorized predicted values pred compared actual values. See mae() details. win_rmse() returns root mean squared error (RMSE) winsorized predicted values pred compared actual values. See rmse() details.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Winsorize a numeric vector — winsorize","text":"","code":"a <- c(3, 5, 2, 7, 9, 4, 6, 8, 2, 10) p <- c(2.5, 5.5, 1.5, 6.5, 10.5, 3.5, 6, 7.5, 0.5, 11.5)  a  # the original data #>  [1]  3  5  2  7  9  4  6  8  2 10 winsorize(a, c(2, 8))  # a winsorized on defined boundaries #>  [1] 3 5 2 7 8 4 6 8 2 8  # range of the original data a #>  [1]  3  5  2  7  9  4  6  8  2 10 range(a) #> [1]  2 10  # some overzealous predictions p #>  [1]  2.5  5.5  1.5  6.5 10.5  3.5  6.0  7.5  0.5 11.5 range(p) #> [1]  0.5 11.5  # MAE penalizes overzealous predictions mae(a, p) #> [1] 0.75  # Winsorized MAE forgives overzealous predictions win_mae(a, p) #> [1] 0.35  # RMSE penalizes overzealous predictions rmse(a, p) #> [1] 0.9082951  # Winsorized RMSE forgives overzealous predictions win_rmse(a, p) #> [1] 0.4743416"},{"path":"https://tripartio.github.io/staccuracy/news/index.html","id":"staccuracy-022","dir":"Changelog","previous_headings":"","what":"staccuracy 0.2.2","title":"staccuracy 0.2.2","text":"CRAN release: 2025-02-23 Add reg_aucroc() function calculate AUC regression models. Corrected bug p-value calculation. Rewrote sa_diff() output separate staccuracies differences. l- Use (r+1)/(n+1) p-value calculation North et al. (2003).","code":""},{"path":"https://tripartio.github.io/staccuracy/news/index.html","id":"staccuracy-020","dir":"Changelog","previous_headings":"","what":"staccuracy 0.2.0","title":"staccuracy 0.2.0","text":"CRAN release: 2024-11-06 Added sa_diff() function bootstrapped-based comparison staccuracies. var_type() longer exported since really internal function.","code":""},{"path":"https://tripartio.github.io/staccuracy/news/index.html","id":"staccuracy-010","dir":"Changelog","previous_headings":"","what":"staccuracy 0.1.0","title":"staccuracy 0.1.0","text":"CRAN release: 2024-10-03 Initial CRAN submission.","code":""}]
