[{"path":"https://tripartio.github.io/staccuracy/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Chitu Okoli Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tripartio.github.io/staccuracy/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Chitu Okoli. Author, maintainer.","code":""},{"path":"https://tripartio.github.io/staccuracy/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Okoli C (2024). staccuracy: Standardized Accuracy Model Performance Metrics. R package version 0.1.0, https://tripartio.github.io/staccuracy/, https://github.com/tripartio/staccuracy.","code":"@Manual{,   title = {staccuracy: Standardized Accuracy and Other Model Performance Metrics},   author = {Chitu Okoli},   year = {2024},   note = {R package version 0.1.0, https://tripartio.github.io/staccuracy/},   url = {https://github.com/tripartio/staccuracy}, }"},{"path":"https://tripartio.github.io/staccuracy/index.html","id":"staccuracy","dir":"","previous_headings":"","what":"Standardized Accuracy and Other Model Performance Metrics","title":"Standardized Accuracy and Other Model Performance Metrics","text":"Standardized accuracy (staccuracy) framework expressing accuracy scores 50% represents reference level performance 100% perfect prediction. staccuracy package provides tools creating staccuracy functions well recommended staccuracy measures. also provides functions classic performance metrics mean absolute error (MAE), root mean squared error (RMSE), area receiver operating characteristic curve (AUCROC), well winsorized versions applicable.","code":""},{"path":"https://tripartio.github.io/staccuracy/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Standardized Accuracy and Other Model Performance Metrics","text":"can install development version staccuracy like :","code":"# install.packages(\"devtools\") devtools::install_github(\"tripartio/staccuracy\")"},{"path":"https://tripartio.github.io/staccuracy/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Standardized Accuracy and Other Model Performance Metrics","text":"basic example shows solve common problem:","code":"library(staccuracy) #>  #> Attaching package: 'staccuracy' #> The following object is masked from 'package:stats': #>  #>     mad  # Here's some data actual_1 <- c(2.3, 4.5, 1.8, 7.6, 3.2)  # Here are some predictions of that data predicted_1 <- c(2.5, 4.2, 1.9, 7.4, 3.0)  # MAE measures the average error in the predictions mae(actual_1, predicted_1) #> [1] 0.2  # But how good is that?  # MAD gives the natural variation in the actual data; this is a point of comparison. mad(actual_1) #> [1] 1.736  # So, our predictions are better (lower) than the MAD, but how good, really? # Create a standardized accuracy function to give us an easily interpretable metric: my_mae_vs_mad_sa <- standardized_accuracy(mae, mad)  # Now use it my_mae_vs_mad_sa(actual_1, predicted_1) #> [1] 0.9423963  # That's 94.2% standardized accuracy compared to the MAD. Pretty good!  # This and other convenient standardized accuracy scores are already built in sa_mae_mad(actual_1, predicted_1)  # staccuracy of MAE on MAD #> [1] 0.9423963 sa_rmse_sd(actual_1, predicted_1)  # staccuracy of RMSE on SD #> [1] 0.95477"},{"path":"https://tripartio.github.io/staccuracy/reference/class-error.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the ROC curve — aucroc","title":"Area under the ROC curve — aucroc","text":"Returns area ROC curve based comparing predicted scores actual binary values. Tied predictions handled calculating optimistic AUC (positive cases sorted first, resulting higher AUC) pessimistic AUC (positive cases sorted last, resulting lower AUC) returning average two. ROC, \"tie\" means least one pair pred predictions whose value identical yet corresponding values actual different. (value actual identical predictions, unproblematic considered \"ties\".)","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/class-error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the ROC curve — aucroc","text":"","code":"aucroc(   actual,   pred,   na.rm = FALSE,   binary_true_value = NULL,   sample_size = 10000,   seed = 0 )"},{"path":"https://tripartio.github.io/staccuracy/reference/class-error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the ROC curve — aucroc","text":"actual atomic vector. Actual label values dataset. must binary; , must exactly two distinct values (missing values, allowed). \"true\" \"positive\" class determined coercing actual logical TRUE FALSE following rules .logical(). intended meaning \"positive\", specify two values considered TRUE argument binary_true_value. pred numeric vector. Predictions corresponding respective element actual. numeric value (probabilities) permissible. na.rm logical(1). TRUE missing values removed; FALSE retained. TRUE, element either actual pred missing, paired element also removed. binary_true_value single atomic value. value actual considered TRUE; value actual considered FALSE. example, 2 means TRUE 1 means FALSE, set binary_true_value = 2. sample_size single positive integer. keep computation relatively rapid, actual pred longer sample_size elements, random sample sample_size actual pred selected ROC AUC calculated sample. disable random sampling long inputs, set sample_size = NA. seed numeric(1). Random seed used length(actual) > sample_size.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/class-error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the ROC curve — aucroc","text":"List following elements: roc_opt: tibble optimistic ROC data. \"Optimistic\" means predictions tied, TRUE/positive actual values ordered FALSE/negative ones. roc_pess: tibble pessimistic ROC data. \"Pessimistic\" means predictions tied, FALSE/negative actual values ordered TRUE/positive ones. Note difference merely sort order: ties, way true positives, true negatives, etc. counted different optimistic pessimistic approaches. tied predictions, roc_opt roc_pess identical. auc_opt: area ROC curve optimistic ROC. auc_pess: area ROC curve pessimistic ROC. auc: mean auc_opt auc_pess. tied predictions, auc_opt, auc_pess, auc identical. ties: TRUE two tied predictions; FALSE ties.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/class-error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the ROC curve — aucroc","text":"","code":"set.seed(0) # Generate some simulated \"actual\" data a <- sample(c(TRUE, FALSE), 50, replace = TRUE)  # Generate some simulated predictions p <- runif(50) |> round(2) p[c(7, 8, 22, 35, 40, 41)] <- 0.5  # Calculate AUCROC with its components ar <- aucroc(a, p) ar$auc #> [1] 0.46875"},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression error and deviation measures — mae","title":"Regression error and deviation measures — mae","text":"standard error deviation measures numeric data. \"Deviation\" means natural variation values numeric vector around central tendency (usually mean median). \"Error\" means average discrepancy actual values numeric vector predicted values.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression error and deviation measures — mae","text":"","code":"mae(actual, pred, na.rm = FALSE)  rmse(actual, pred, na.rm = FALSE)  mad(x, na.rm = FALSE, version = \"mean\", ...)"},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression error and deviation measures — mae","text":"actual numeric vector. Actual (true) values target outcome data. pred numeric vector. Predictions corresponding respective element actual. na.rm logical(1). TRUE missing values removed; FALSE retained. TRUE, element either actual pred missing, paired element also removed. x numeric vector. Values calculate MAD. version character(1). default (version = 'mean'), mad() returns mean absolute deviation (MAD) values relative mean. version = 'median', calls stats::mad() function instead, median absolute deviation relative median (MedAD, sometimes also called MAD). value gives error. See details. ... Arguments pass stats::mad() version = 'median'. See version argument details.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression error and deviation measures — mae","text":"cases, value actual pred NA na.rm = FALSE, function returns NA. mae() returns mean absolute error (MAE) predicted values pred compared actual values. rmse() returns root mean squared error (RMSE) predicted values pred compared actual values. mad() returns either mean absolute deviation (MAD) values relative mean (default) median absolute deviation relative median. See details.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regression error and deviation measures — mae","text":"Mean absolute deviation (MAD) mad() returns mean absolute deviation (MAD) values relative mean. useful default benchmark mean absolute error (MAE), standard deviation (SD) default benchmark root mean square error (RMSE). NOTE: function name overrides stats::mad() (median absolute deviation relative median). maintain functionality stats::mad(), specify version argument.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/reg-error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression error and deviation measures — mae","text":"","code":"a <- c(3, 5, 2, 7, 9, 4, 6, 8, 1, 10) p <- c(2.5, 5.5, 2, 6.5, 9.5, 3.5, 6, 7.5, 1.5, 9.5) mae(a, p) #> [1] 0.4  rmse(a, p) #> [1] 0.4472136  mad(a) #> [1] 2.5"},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized Accuracy and Other Model Performance Metrics — staccuracy-package","title":"Standardized Accuracy and Other Model Performance Metrics — staccuracy-package","text":"Standardized accuracy (staccuracy) framework expressing accuracy scores 50% represents reference level performance 100% perfect prediction. 'staccuracy' package provides tools creating staccuracy functions well recommended staccuracy measures. also provides functions classic performance metrics mean absolute error (MAE), root mean squared error (RMSE), area receiver operating characteristic curve (AUCROC), well winsorized versions applicable.","code":""},{"path":[]},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Standardized Accuracy and Other Model Performance Metrics — staccuracy-package","text":"Chitu Okoli Chitu.Okoli@skema.edu","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","title":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","text":"Standardized accuracy (staccuracy) represents error accuracy measures scale 1 100% means perfect prediction 0.5 50% reference comparison specified standard performance. Higher 0.5 better reference 0.5 worse. 0 might might special meaning; sometimes negative scores possible, often indicate modelling errors. core function standardized_accuracy(), receives input generic error function reference function compare error function performance. addition, following recommended staccuracy functions provided: sa_mae_mad: standardized accuracy mean absolute error (MAE) based mean absolute deviation (MAD) sa_rmse_sd: standardized accuracy root mean squared error (RMSE) based standard deviation (SD) sa_wmae_mad: standardized accuracy winsorized mean absolute error (MAE) based mean absolute deviation (MAD) sa_wrmse_sd: standardized accuracy winsorized root mean squared error (RMSE) based standard deviation (SD)","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","text":"","code":"standardized_accuracy(error_fun, ref_fun)  sa_mae_mad(actual, pred, na.rm = FALSE)  sa_wmae_mad(actual, pred, na.rm = FALSE)  sa_rmse_sd(actual, pred, na.rm = FALSE)  sa_wrmse_sd(actual, pred, na.rm = FALSE)"},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","text":"error_fun function. unquoted name function calculates error (accuracy) measure. function must signature function(actual, pred, na.rm = FALSE). ref_fun function. unquoted name function calculates reference error, accuracy, deviation measure. function must signature ref_fun(actual, na.rm = FALSE). actual numeric. true (actual) labels. pred numeric. predicted estimates. Must length actual. na.rm logical(1). Whether NA values removed (TRUE) (FALSE, default).","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","text":"standardized_accuracy() returns function signature function(actual, pred, na.rm = FALSE) receives actual pred vector inputs returns staccuracy originally input error function based input reference function. convenience sa_*() functions return staccuracy measures specified .","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","text":"core function standardized_accuracy() receives input generic error function reference function compare error function's performance. input functions must following signatures (see argument specifications details arguments): error_fun: function(actual, pred, na.rm = na.rm); output must scalar numeric (, single number). error_fun: function(actual, pred, na.rm = na.rm); output must scalar numeric (, single number).","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/staccuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardized accuracy (staccuracy) functions. — standardized_accuracy","text":"","code":"# Here's some data actual_1 <- c(2.3, 4.5, 1.8, 7.6, 3.2)  # Here are some predictions of that data predicted_1 <- c(2.5, 4.2, 1.9, 7.4, 3.0)  # MAE measures the average error in the predictions mae(actual_1, predicted_1) #> [1] 0.2  # But how good is that? # MAD gives the natural variation in the actual data; this is a point of comparison. mad(actual_1) #> [1] 1.736  # So, our predictions are better (lower) than the MAD, but how good, really? # Create a standardized accuracy function to give us an easily interpretable metric: my_mae_vs_mad_sa <- standardized_accuracy(mae, mad)  # Now use it my_mae_vs_mad_sa(actual_1, predicted_1) #> [1] 0.9423963  # That's 94.2% standardized accuracy compared to the MAD. Pretty good!"},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":null,"dir":"Reference","previous_headings":"","what":"Winsorize a numeric vector — winsorize","title":"Winsorize a numeric vector — winsorize","text":"Winsorization means truncating extremes numeric range replacing extreme values predetermined minimum maximum. winsorize() returns input vector values values less greater provided minimum maximum replaced provided minimum maximum, respectively. win_mae() win_rmse() return MAE RMSE respectively winsorized predictions. fundamental idea underlying winsorization predictions actual data well-defined bounds, models penalized overzealous predicting beyond extremes data. Models overzealous boundaries might sometimes superior within normal ranges; extremes can easily corrected winsorization.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Winsorize a numeric vector — winsorize","text":"","code":"winsorize(x, win_range)  win_mae(actual, pred, win_range = range(actual), na.rm = FALSE)  win_rmse(actual, pred, win_range = range(actual), na.rm = FALSE)"},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Winsorize a numeric vector — winsorize","text":"x numeric vector. win_range numeric(2). minimum maximum allowable values pred predictions x. functions pred, win_range defaults minimum maximum values provided actual values. functions x, default. actual numeric vector. Actual (true) values target outcome data. pred numeric vector. Predictions corresponding respective element actual. na.rm logical(1). TRUE missing values removed; FALSE retained. TRUE, element either actual pred missing, paired element also removed.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Winsorize a numeric vector — winsorize","text":"winsorize() returns winsorized vector. win_mae() returns mean absolute error (MAE) winsorized predicted values pred compared actual values. See mae() details. win_rmse() returns root mean squared error (RMSE) winsorized predicted values pred compared actual values. See rmse() details.","code":""},{"path":"https://tripartio.github.io/staccuracy/reference/win-error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Winsorize a numeric vector — winsorize","text":"","code":"a <- c(3, 5, 2, 7, 9, 4, 6, 8, 2, 10) p <- c(2.5, 5.5, 1.5, 6.5, 10.5, 3.5, 6, 7.5, 0.5, 11.5)  a  # the original data #>  [1]  3  5  2  7  9  4  6  8  2 10 winsorize(a, c(2, 8))  # a winsorized on defined boundaries #>  [1] 3 5 2 7 8 4 6 8 2 8  # range of the original data a #>  [1]  3  5  2  7  9  4  6  8  2 10 range(a) #> [1]  2 10  # some overzealous predictions p #>  [1]  2.5  5.5  1.5  6.5 10.5  3.5  6.0  7.5  0.5 11.5 range(p) #> [1]  0.5 11.5  # MAE penalizes overzealous predictions mae(a, p) #> [1] 0.75  # Winsorized MAE forgives overzealous predictions win_mae(a, p) #> [1] 0.35  # RMSE penalizes overzealous predictions rmse(a, p) #> [1] 0.9082951  # Winsorized RMSE forgives overzealous predictions win_rmse(a, p) #> [1] 0.4743416"},{"path":"https://tripartio.github.io/staccuracy/news/index.html","id":"staccuracy-010","dir":"Changelog","previous_headings":"","what":"staccuracy 0.1.0","title":"staccuracy 0.1.0","text":"Initial CRAN submission.","code":""}]
